{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import FinanceDataReader as fdr\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tickers from: /home/dave/projects/dev_backend/데이터/README/list.csv\n",
      "✓ Successfully loaded 200 stocks\n",
      "\n",
      "First few rows:\n",
      "    종목코드     종목명       종가    대비   등락률       상장시가총액\n",
      "0   5930    삼성전자  1330000  3000  0.23  195908118.0\n",
      "1   5380     현대차   169000     0  0.00   37226725.0\n",
      "2    660  SK하이닉스    47750     0  0.00   34762113.0\n",
      "3  15760    한국전력    42700     0  0.00   27411866.0\n",
      "4   5490   POSCO   283500  8000  2.90   24717468.0\n",
      "\n",
      "✓ Extracted 200 tickers\n",
      "First 5 tickers: ['005930', '005380', '000660', '015760', '005490']\n"
     ]
    }
   ],
   "source": [
    "# 경로\n",
    "list_path = '/home/dave/projects/dev_backend/데이터/README/list.csv'\n",
    "\n",
    "print(f\"Loading tickers from: {list_path}\")\n",
    "\n",
    "# 한글 지원을 위해 encoding cp949 사용\n",
    "ticker_df = pd.read_csv(list_path, encoding='cp949')\n",
    "\n",
    "print(f\"✓ Successfully loaded {len(ticker_df)} stocks\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(ticker_df.head())\n",
    "\n",
    "# 종목 ticker코드를 0을 사용해서 6자 유지\n",
    "tickers = ticker_df.iloc[:, 0].astype(str).str.zfill(6).tolist()\n",
    "\n",
    "print(f\"\\n✓ Extracted {len(tickers)} tickers\")\n",
    "print(f\"First 5 tickers: {tickers[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collection period: 2015-01-01 to 2024-12-31\n",
      "Number of stocks to download: 200\n"
     ]
    }
   ],
   "source": [
    "# 날짜 설정\n",
    "start_date = '2015-01-01'\n",
    "end_date = '2024-12-31'\n",
    "\n",
    "print(f\"Data collection period: {start_date} to {end_date}\")\n",
    "print(f\"Number of stocks to download: {len(tickers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:15<00:00, 12.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Downloaded: 200 stocks\n",
      "✗ Failed: 0 stocks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 종목 OHLCV\n",
    "all_data = []\n",
    "failed_tickers = []\n",
    "\n",
    "print(\"Starting data collection...\\n\")\n",
    "\n",
    "for ticker in tqdm(tickers):\n",
    "    try:\n",
    "        df = fdr.DataReader(ticker, start_date, end_date)\n",
    "        \n",
    "        if not df.empty:\n",
    "            # Ticker column 추가\n",
    "            df['Ticker'] = ticker\n",
    "            df = df.reset_index()\n",
    "            \n",
    "            all_data.append(df)\n",
    "        else:\n",
    "            failed_tickers.append(ticker)\n",
    "            \n",
    "    except Exception as e:\n",
    "        failed_tickers.append(ticker)\n",
    "        print(f\"Error: {ticker} - {e}\")\n",
    "\n",
    "print(f\"\\n✓ Downloaded: {len(all_data)} stocks\")\n",
    "print(f\"✗ Failed: {len(failed_tickers)} stocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame shape: (471300, 8)\n",
      "\n",
      "Date range: 2015-01-02 00:00:00 to 2024-12-30 00:00:00\n",
      "Number of unique stocks: 200\n",
      "\n",
      "First few rows:\n",
      "        Date   Open   High   Low  Close   Volume    Change  Ticker\n",
      "0 2015-01-02  10000  10000  9760   9790  2918197 -0.021000  000030\n",
      "1 2015-01-05   9750   9760  9530   9630  3563551 -0.016343  000030\n",
      "2 2015-01-06   9520   9580  9410   9440  2619991 -0.019730  000030\n",
      "3 2015-01-07   9380   9510  9370   9400  1679442 -0.004237  000030\n",
      "4 2015-01-08   9420   9620  9410   9530  2166767  0.013830  000030\n",
      "5 2015-01-09   9630   9660  9510   9560  1737936  0.003148  000030\n",
      "6 2015-01-12   9500   9540  9360   9380  1449448 -0.018828  000030\n",
      "7 2015-01-13   9400   9490  9320   9390  1380551  0.001066  000030\n",
      "8 2015-01-14   9390   9420  9190   9220  2399519 -0.018104  000030\n",
      "9 2015-01-15   9190   9200  9000   9050  2884385 -0.018438  000030\n"
     ]
    }
   ],
   "source": [
    "# DataFrame 하나로 정리\n",
    "if all_data:\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Ticker & Date로 정리\n",
    "    combined_df = combined_df.sort_values(['Ticker', 'Date']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Combined DataFrame shape: {combined_df.shape}\")\n",
    "    print(f\"\\nDate range: {combined_df['Date'].min()} to {combined_df['Date'].max()}\")\n",
    "    print(f\"Number of unique stocks: {combined_df['Ticker'].nunique()}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(combined_df.head(10))\n",
    "else:\n",
    "    print(\"No data collected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rolling returns...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating returns: 100%|██████████| 200/200 [00:04<00:00, 42.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Added rolling return features\n",
      "Return columns: ['Return_1d', 'Return_5d', 'Return_20d', 'Return_30d', 'Return_50d', 'Return_60d', 'Return_100d', 'Return_120d', 'Return_200d']\n",
      "\n",
      "DataFrame shape: (471300, 17)\n",
      "Total columns: 17\n",
      "\n",
      "================================================================================\n",
      "Sample: First 10 rows of first stock\n",
      "================================================================================\n",
      "        Date  Close  Return_1d  Return_5d  Return_20d  Return_60d\n",
      "0 2015-01-02   9790   0.000000   0.000000         0.0         0.0\n",
      "1 2015-01-05   9630  -1.634321   0.000000         0.0         0.0\n",
      "2 2015-01-06   9440  -1.973001   0.000000         0.0         0.0\n",
      "3 2015-01-07   9400  -0.423729   0.000000         0.0         0.0\n",
      "4 2015-01-08   9530   1.382979   0.000000         0.0         0.0\n",
      "5 2015-01-09   9560   0.314795  -2.349336         0.0         0.0\n",
      "6 2015-01-12   9380  -1.882845  -2.596054         0.0         0.0\n",
      "7 2015-01-13   9390   0.106610  -0.529661         0.0         0.0\n",
      "8 2015-01-14   9220  -1.810437  -1.914894         0.0         0.0\n",
      "9 2015-01-15   9050  -1.843818  -5.036726         0.0         0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating rolling returns...\\n\")\n",
    "\n",
    "# Rolling window 설정\n",
    "return_windows = [1, 5, 20, 30, 50, 60, 100, 120, 200]\n",
    "\n",
    "all_stocks_with_returns = []\n",
    "\n",
    "for ticker in tqdm(combined_df['Ticker'].unique(), desc=\"Calculating returns\"):\n",
    "    # 종목별 계산\n",
    "    stock_df = combined_df[combined_df['Ticker'] == ticker].copy()\n",
    "    stock_df = stock_df.sort_values('Date').reset_index(drop=True)\n",
    "    \n",
    "    # Rolling window 설정 계산\n",
    "    for window in return_windows:\n",
    "        # Return = (오늘 종가 - N일 전 종가) / N일 전 종가 * 100\n",
    "        stock_df[f'Return_{window}d'] = stock_df['Close'].pct_change(periods=window) * 100\n",
    "        \n",
    "        # 첫 N일, fill NaN 0으로\n",
    "        stock_df[f'Return_{window}d'] = stock_df[f'Return_{window}d'].fillna(0)\n",
    "    \n",
    "    all_stocks_with_returns.append(stock_df)\n",
    "\n",
    "# 모든 종목 수익률 계산\n",
    "combined_df_with_returns = pd.concat(all_stocks_with_returns, ignore_index=True)\n",
    "\n",
    "print(f\"\\n✓ Added rolling return features\")\n",
    "print(f\"Return columns: {[col for col in combined_df_with_returns.columns if 'Return_' in col]}\")\n",
    "print(f\"\\nDataFrame shape: {combined_df_with_returns.shape}\")\n",
    "print(f\"Total columns: {len(combined_df_with_returns.columns)}\")\n",
    "\n",
    "# 샘플 데이터\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Sample: First 10 rows of first stock\")\n",
    "print(f\"{'='*80}\")\n",
    "sample = combined_df_with_returns[combined_df_with_returns['Ticker'] == combined_df_with_returns['Ticker'].iloc[0]].head(10)\n",
    "print(sample[['Date', 'Close', 'Return_1d', 'Return_5d', 'Return_20d', 'Return_60d']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating volume pattern features...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding volume features: 100%|██████████| 200/200 [00:04<00:00, 45.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Added volume pattern features\n",
      "Volume columns: ['vol_20', 'vol_60', 'vol_60_sqrt252', 'log_vol', 'vol_ratio_60', 'avg_log_vol_ratio_60', 'std_log_vol_ratio_60']\n",
      "\n",
      "DataFrame shape: (471300, 24)\n",
      "Total columns: 24\n",
      "\n",
      "================================================================================\n",
      "Sample: First 10 rows showing volume features\n",
      "================================================================================\n",
      "        Date   Volume    log_vol    vol_20    vol_60  vol_ratio_60\n",
      "0 2015-01-02  2918197  14.886477  0.000000  0.000000      0.000000\n",
      "1 2015-01-05  3563551  15.086268  0.000000  0.000000      0.099896\n",
      "2 2015-01-06  2619991  14.778682  0.002395  0.002395     -0.138461\n",
      "3 2015-01-07  1679442  14.333973  0.008145  0.008145     -0.437377\n",
      "4 2015-01-08  2166767  14.588747  0.015169  0.015169     -0.146082\n",
      "5 2015-01-09  1737936  14.368209  0.013844  0.013844     -0.305517\n",
      "6 2015-01-12  1449448  14.186694  0.013666  0.013666     -0.417456\n",
      "7 2015-01-13  1380551  14.137994  0.012845  0.012845     -0.407887\n",
      "8 2015-01-14  2399519  14.690779  0.012654  0.012654      0.128799\n",
      "9 2015-01-15  2884385  14.874823  0.012395  0.012395      0.281558\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating volume pattern features...\\n\")\n",
    "\n",
    "all_stocks_with_volume = []\n",
    "\n",
    "for ticker in tqdm(combined_df_with_returns['Ticker'].unique(), desc=\"Adding volume features\"):\n",
    "    # 종목별 계산\n",
    "    stock_df = combined_df_with_returns[combined_df_with_returns['Ticker'] == ticker].copy()\n",
    "    stock_df = stock_df.sort_values('Date').reset_index(drop=True)\n",
    "    \n",
    "    # 1. vol_20 - 20-day rolling volatility\n",
    "    stock_df['vol_20'] = stock_df['Close'].pct_change().rolling(window=20, min_periods=1).std()\n",
    "    \n",
    "    # 2. vol_60 - 60-day rolling volatility\n",
    "    stock_df['vol_60'] = stock_df['Close'].pct_change().rolling(window=60, min_periods=1).std()\n",
    "    \n",
    "    # 3. vol_60_sqrt252 - 60-day volatility * sqrt(252) for annualization\n",
    "    stock_df['vol_60_sqrt252'] = stock_df['vol_60'] * np.sqrt(252)\n",
    "    \n",
    "    # 4. log_vol - Log of volume\n",
    "    stock_df['log_vol'] = np.log(stock_df['Volume'] + 1)  # +1 to avoid log(0)\n",
    "    \n",
    "    # 5. vol_ratio_60 - Log volume ratio vs 60-day mean\n",
    "    log_vol_mean_60 = stock_df['log_vol'].rolling(window=60, min_periods=1).mean()\n",
    "    stock_df['vol_ratio_60'] = stock_df['log_vol'] - log_vol_mean_60\n",
    "    \n",
    "    # 6. avg_log_vol_ratio_60 - Average of vol_ratio_60\n",
    "    stock_df['avg_log_vol_ratio_60'] = stock_df['vol_ratio_60'].rolling(window=60, min_periods=1).mean()\n",
    "    \n",
    "    # 7. std_log_vol_ratio_60 - Standard deviation of vol_ratio_60\n",
    "    stock_df['std_log_vol_ratio_60'] = stock_df['vol_ratio_60'].rolling(window=60, min_periods=1).std()\n",
    "    \n",
    "    # Fill NaN 0으로\n",
    "    stock_df[['vol_20', 'vol_60', 'vol_60_sqrt252', 'log_vol', 'vol_ratio_60', \n",
    "              'avg_log_vol_ratio_60', 'std_log_vol_ratio_60']] = stock_df[['vol_20', 'vol_60', 'vol_60_sqrt252', \n",
    "              'log_vol', 'vol_ratio_60', 'avg_log_vol_ratio_60', 'std_log_vol_ratio_60']].fillna(0)\n",
    "    \n",
    "    all_stocks_with_volume.append(stock_df)\n",
    "\n",
    "# 모든 종목에 vol 추가\n",
    "combined_df_final = pd.concat(all_stocks_with_volume, ignore_index=True)\n",
    "\n",
    "print(f\"\\n✓ Added volume pattern features\")\n",
    "volume_cols = ['vol_20', 'vol_60', 'vol_60_sqrt252', 'log_vol', 'vol_ratio_60', 'avg_log_vol_ratio_60', 'std_log_vol_ratio_60']\n",
    "print(f\"Volume columns: {volume_cols}\")\n",
    "print(f\"\\nDataFrame shape: {combined_df_final.shape}\")\n",
    "print(f\"Total columns: {len(combined_df_final.columns)}\")\n",
    "\n",
    "# 샘플 데이터\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Sample: First 10 rows showing volume features\")\n",
    "print(f\"{'='*80}\")\n",
    "sample = combined_df_final[combined_df_final['Ticker'] == combined_df_final['Ticker'].iloc[0]].head(10)\n",
    "print(sample[['Date', 'Volume', 'log_vol', 'vol_20', 'vol_60', 'vol_ratio_60']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving individual stock files with all features...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving files: 100%|██████████| 200/200 [00:03<00:00, 54.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved 200 individual stock files to 'data/' folder\n",
      "Each file has Date as index\n",
      "Columns per file: 22 (OHLCV + Returns + Volume features)\n",
      "\n",
      "First 5 files:\n",
      "  - 000030_우리은행.parquet\n",
      "  - 000070_삼양홀딩스.parquet\n",
      "  - 000080_하이트진로.parquet\n",
      "  - 000100_유한양행.parquet\n",
      "  - 000120_CJ대한통운.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# data 폴더 생성\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "print(\"Saving individual stock files with all features...\\n\")\n",
    "\n",
    "for ticker in tqdm(combined_df_final['Ticker'].unique(), desc=\"Saving files\"):\n",
    "    # Ticker로 종목 선정\n",
    "    stock_data = combined_df_final[combined_df_final['Ticker'] == ticker].copy()\n",
    "    \n",
    "    # Date index로 설정\n",
    "    stock_data = stock_data.set_index('Date').sort_index()\n",
    "    \n",
    "    # Ticker 중복 column 제거\n",
    "    stock_data = stock_data.drop('Ticker', axis=1)\n",
    "    \n",
    "    # ticker_df에서 종목명 추출\n",
    "    stock_name = ticker_df[ticker_df.iloc[:, 0].astype(str).str.zfill(6) == ticker].iloc[:, 1].values[0] if len(ticker_df[ticker_df.iloc[:, 0].astype(str).str.zfill(6) == ticker]) > 0 else \"Unknown\"\n",
    "    \n",
    "    # 파일 이름 설정\n",
    "    filename = f\"{ticker}_{stock_name}.parquet\"\n",
    "    filepath = os.path.join('data', filename)\n",
    "    \n",
    "    # parquet으로 저장\n",
    "    stock_data.to_parquet(filepath, compression='snappy')\n",
    "\n",
    "print(f\"\\n✓ Saved {len(combined_df_final['Ticker'].unique())} individual stock files to 'data/' folder\")\n",
    "print(f\"Each file has Date as index\")\n",
    "print(f\"Columns per file: {len(stock_data.columns)} (OHLCV + Returns + Volume features)\")\n",
    "\n",
    "# 5종목 샘플\n",
    "files = sorted(os.listdir('data'))\n",
    "print(f\"\\nFirst 5 files:\")\n",
    "for f in files[:5]:\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 parquet files\n",
      "\n",
      "Sample file: 002240_고려제강.parquet\n",
      "Shape: (2458, 22)\n",
      "\n",
      "Columns: ['Open', 'High', 'Low', 'Close', 'Volume', 'Change', 'Return_1d', 'Return_5d', 'Return_20d', 'Return_30d', 'Return_50d', 'Return_60d', 'Return_100d', 'Return_120d', 'Return_200d', 'vol_20', 'vol_60', 'vol_60_sqrt252', 'log_vol', 'vol_ratio_60', 'avg_log_vol_ratio_60', 'std_log_vol_ratio_60']\n",
      "\n",
      "First 10 rows:\n",
      "             Open   High    Low  Close  Volume    Change  Return_1d  \\\n",
      "Date                                                                  \n",
      "2015-01-02  27916  28017  27415  27617   27714 -0.021333   0.000000   \n",
      "2015-01-05  27615  27715  26378  26916   34948 -0.025383  -2.538292   \n",
      "2015-01-06  26715  27050  26481  26850   18115 -0.002452  -0.245207   \n",
      "2015-01-07  26848  27216  26581  26783   20686 -0.002495  -0.249534   \n",
      "2015-01-08  26981  27049  26681  26716   11595 -0.002502  -0.250159   \n",
      "2015-01-09  26746  27514  26746  27383   11730  0.024966   2.496631   \n",
      "2015-01-12  27115  27682  27049  27217   14146 -0.006062  -0.606216   \n",
      "2015-01-13  27215  27315  26881  27150   16861 -0.002462  -0.246170   \n",
      "2015-01-14  26982  27016  26682  26983   19170 -0.006151  -0.615101   \n",
      "2015-01-15  26817  26817  26649  26817   10626 -0.006152  -0.615202   \n",
      "\n",
      "            Return_5d  Return_20d  Return_30d  ...  Return_100d  Return_120d  \\\n",
      "Date                                           ...                             \n",
      "2015-01-02   0.000000         0.0         0.0  ...          0.0          0.0   \n",
      "2015-01-05   0.000000         0.0         0.0  ...          0.0          0.0   \n",
      "2015-01-06   0.000000         0.0         0.0  ...          0.0          0.0   \n",
      "2015-01-07   0.000000         0.0         0.0  ...          0.0          0.0   \n",
      "2015-01-08   0.000000         0.0         0.0  ...          0.0          0.0   \n",
      "2015-01-09  -0.847304         0.0         0.0  ...          0.0          0.0   \n",
      "2015-01-12   1.118294         0.0         0.0  ...          0.0          0.0   \n",
      "2015-01-13   1.117318         0.0         0.0  ...          0.0          0.0   \n",
      "2015-01-14   0.746742         0.0         0.0  ...          0.0          0.0   \n",
      "2015-01-15   0.378051         0.0         0.0  ...          0.0          0.0   \n",
      "\n",
      "            Return_200d    vol_20    vol_60  vol_60_sqrt252    log_vol  \\\n",
      "Date                                                                     \n",
      "2015-01-02          0.0  0.000000  0.000000        0.000000  10.229729   \n",
      "2015-01-05          0.0  0.000000  0.000000        0.000000  10.461645   \n",
      "2015-01-06          0.0  0.016215  0.016215        0.257398   9.804551   \n",
      "2015-01-07          0.0  0.013227  0.013227        0.209967   9.937261   \n",
      "2015-01-08          0.0  0.011450  0.011450        0.181763   9.358415   \n",
      "2015-01-09          0.0  0.017845  0.017845        0.283276   9.369990   \n",
      "2015-01-12          0.0  0.016066  0.016066        0.255034   9.557258   \n",
      "2015-01-13          0.0  0.014666  0.014666        0.232815   9.732818   \n",
      "2015-01-14          0.0  0.013645  0.013645        0.216603   9.861154   \n",
      "2015-01-15          0.0  0.012812  0.012812        0.203380   9.271153   \n",
      "\n",
      "            vol_ratio_60  avg_log_vol_ratio_60  std_log_vol_ratio_60  \n",
      "Date                                                                  \n",
      "2015-01-02      0.000000              0.000000              0.000000  \n",
      "2015-01-05      0.115958              0.057979              0.081995  \n",
      "2015-01-06     -0.360758             -0.081600              0.248613  \n",
      "2015-01-07     -0.171036             -0.103959              0.207859  \n",
      "2015-01-08     -0.599905             -0.203148              0.285651  \n",
      "2015-01-09     -0.490275             -0.251002              0.281100  \n",
      "2015-01-12     -0.259721             -0.252248              0.256630  \n",
      "2015-01-13     -0.073641             -0.229922              0.245841  \n",
      "2015-01-14      0.048618             -0.198973              0.247999  \n",
      "2015-01-15     -0.487244             -0.227800              0.250958  \n",
      "\n",
      "[10 rows x 22 columns]\n",
      "\n",
      "✓ Files saved with 22 columns including returns!\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러와지는 확인\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_folder = 'data'\n",
    "parquet_files = [f for f in os.listdir(data_folder) if f.endswith('.parquet')]\n",
    "\n",
    "print(f\"Found {len(parquet_files)} parquet files\\n\")\n",
    "\n",
    "sample_file = parquet_files[0]\n",
    "sample_df = pd.read_parquet(os.path.join(data_folder, sample_file))\n",
    "\n",
    "print(f\"Sample file: {sample_file}\")\n",
    "print(f\"Shape: {sample_df.shape}\")\n",
    "print(f\"\\nColumns: {list(sample_df.columns)}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(sample_df.head(10))\n",
    "\n",
    "print(f\"\\n✓ Files saved with {len(sample_df.columns)} columns including returns!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
