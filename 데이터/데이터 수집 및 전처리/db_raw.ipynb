{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import FinanceDataReader as fdr\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tickers from: /home/dave/projects/dev_backend/데이터/README/list.csv\n",
      "✓ Successfully loaded 200 stocks\n",
      "\n",
      "First few rows:\n",
      "    종목코드     종목명       종가    대비   등락률       상장시가총액\n",
      "0   5930    삼성전자  1330000  3000  0.23  195908118.0\n",
      "1   5380     현대차   169000     0  0.00   37226725.0\n",
      "2    660  SK하이닉스    47750     0  0.00   34762113.0\n",
      "3  15760    한국전력    42700     0  0.00   27411866.0\n",
      "4   5490   POSCO   283500  8000  2.90   24717468.0\n",
      "\n",
      "✓ Extracted 200 tickers\n",
      "First 5 tickers: ['005930', '005380', '000660', '015760', '005490']\n"
     ]
    }
   ],
   "source": [
    "# Load ticker list from list.csv\n",
    "import os\n",
    "\n",
    "# Direct path to list.csv\n",
    "list_path = '/home/dave/projects/dev_backend/데이터/README/list.csv'\n",
    "\n",
    "print(f\"Loading tickers from: {list_path}\")\n",
    "\n",
    "# Load the CSV with cp949 encoding for Korean characters\n",
    "ticker_df = pd.read_csv(list_path, encoding='cp949')\n",
    "\n",
    "print(f\"✓ Successfully loaded {len(ticker_df)} stocks\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(ticker_df.head())\n",
    "\n",
    "# Extract ticker codes (첫 번째 컬럼) and pad with zeros to 6 digits\n",
    "tickers = ticker_df.iloc[:, 0].astype(str).str.zfill(6).tolist()\n",
    "\n",
    "print(f\"\\n✓ Extracted {len(tickers)} tickers\")\n",
    "print(f\"First 5 tickers: {tickers[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collection period: 2015-01-01 to 2024-12-31\n",
      "Number of stocks to download: 200\n"
     ]
    }
   ],
   "source": [
    "# Set date range\n",
    "start_date = '2015-01-01'\n",
    "end_date = '2024-12-31'\n",
    "\n",
    "print(f\"Data collection period: {start_date} to {end_date}\")\n",
    "print(f\"Number of stocks to download: {len(tickers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:18<00:00, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Downloaded: 200 stocks\n",
      "✗ Failed: 0 stocks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download OHLCV data for all stocks\n",
    "all_data = []\n",
    "failed_tickers = []\n",
    "\n",
    "print(\"Starting data collection...\\n\")\n",
    "\n",
    "for ticker in tqdm(tickers):\n",
    "    try:\n",
    "        # Download stock data using FinanceDataReader\n",
    "        df = fdr.DataReader(ticker, start_date, end_date)\n",
    "        \n",
    "        if not df.empty:\n",
    "            # Add Ticker column\n",
    "            df['Ticker'] = ticker\n",
    "            df = df.reset_index()\n",
    "            \n",
    "            all_data.append(df)\n",
    "        else:\n",
    "            failed_tickers.append(ticker)\n",
    "            \n",
    "    except Exception as e:\n",
    "        failed_tickers.append(ticker)\n",
    "        print(f\"Error: {ticker} - {e}\")\n",
    "\n",
    "print(f\"\\n✓ Downloaded: {len(all_data)} stocks\")\n",
    "print(f\"✗ Failed: {len(failed_tickers)} stocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame shape: (471300, 8)\n",
      "\n",
      "Date range: 2015-01-02 00:00:00 to 2024-12-30 00:00:00\n",
      "Number of unique stocks: 200\n",
      "\n",
      "First few rows:\n",
      "        Date   Open   High   Low  Close   Volume    Change  Ticker\n",
      "0 2015-01-02  10000  10000  9760   9790  2918197 -0.021000  000030\n",
      "1 2015-01-05   9750   9760  9530   9630  3563551 -0.016343  000030\n",
      "2 2015-01-06   9520   9580  9410   9440  2619991 -0.019730  000030\n",
      "3 2015-01-07   9380   9510  9370   9400  1679442 -0.004237  000030\n",
      "4 2015-01-08   9420   9620  9410   9530  2166767  0.013830  000030\n",
      "5 2015-01-09   9630   9660  9510   9560  1737936  0.003148  000030\n",
      "6 2015-01-12   9500   9540  9360   9380  1449448 -0.018828  000030\n",
      "7 2015-01-13   9400   9490  9320   9390  1380551  0.001066  000030\n",
      "8 2015-01-14   9390   9420  9190   9220  2399519 -0.018104  000030\n",
      "9 2015-01-15   9190   9200  9000   9050  2884385 -0.018438  000030\n",
      "\n",
      "Data types:\n",
      "Date      datetime64[ns]\n",
      "Open               int64\n",
      "High               int64\n",
      "Low                int64\n",
      "Close              int64\n",
      "Volume             int64\n",
      "Change           float64\n",
      "Ticker            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Combine all data into one DataFrame\n",
    "if all_data:\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Sort by Ticker and Date\n",
    "    combined_df = combined_df.sort_values(['Ticker', 'Date']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Combined DataFrame shape: {combined_df.shape}\")\n",
    "    print(f\"\\nDate range: {combined_df['Date'].min()} to {combined_df['Date'].max()}\")\n",
    "    print(f\"Number of unique stocks: {combined_df['Ticker'].nunique()}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(combined_df.head(10))\n",
    "    print(f\"\\nData types:\")\n",
    "    print(combined_df.dtypes)\n",
    "else:\n",
    "    print(\"No data collected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "Date      0\n",
      "Open      0\n",
      "High      0\n",
      "Low       0\n",
      "Close     0\n",
      "Volume    0\n",
      "Change    0\n",
      "Ticker    0\n",
      "dtype: int64\n",
      "\n",
      "Total missing values: 0\n",
      "\n",
      "==================================================\n",
      "Basic Statistics:\n",
      "==================================================\n",
      "               Open          High           Low         Close        Volume\n",
      "count  4.713000e+05  4.713000e+05  4.713000e+05  4.713000e+05  4.713000e+05\n",
      "mean   8.339571e+04  8.467511e+04  8.212201e+04  8.355240e+04  5.737874e+05\n",
      "std    1.477938e+05  1.499914e+05  1.456154e+05  1.477575e+05  2.069512e+06\n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  9.000000e+01  0.000000e+00\n",
      "25%    1.340000e+04  1.365000e+04  1.320000e+04  1.362425e+04  4.904875e+04\n",
      "50%    3.657350e+04  3.710000e+04  3.605000e+04  3.670000e+04  1.501130e+05\n",
      "75%    8.103100e+04  8.220000e+04  7.990000e+04  8.120000e+04  4.404748e+05\n",
      "max    2.124000e+06  2.407000e+06  1.756000e+06  2.000000e+06  1.745905e+08\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(combined_df.isnull().sum())\n",
    "print(f\"\\nTotal missing values: {combined_df.isnull().sum().sum()}\")\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Basic Statistics:\")\n",
    "print(\"=\"*50)\n",
    "print(combined_df[['Open', 'High', 'Low', 'Close', 'Volume']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving individual stock files...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving files: 100%|██████████| 200/200 [00:02<00:00, 83.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved 200 individual stock files to 'data/' folder\n",
      "\n",
      "First 10 files:\n",
      "  - 000030_우리은행.parquet\n",
      "  - 000070_삼양홀딩스.parquet\n",
      "  - 000080_하이트진로.parquet\n",
      "  - 000100_유한양행.parquet\n",
      "  - 000120_CJ대한통운.parquet\n",
      "  - 000140_하이트진로홀딩스.parquet\n",
      "  - 000150_두산.parquet\n",
      "  - 000210_대림산업.parquet\n",
      "  - 000240_한국타이어월드와이드.parquet\n",
      "  - 000270_기아차.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Save individual parquet files for each stock\n",
    "import os\n",
    "\n",
    "# Create data folder\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "print(\"Saving individual stock files...\\n\")\n",
    "\n",
    "for ticker in tqdm(combined_df['Ticker'].unique(), desc=\"Saving files\"):\n",
    "    # Get data for this ticker\n",
    "    stock_data = combined_df[combined_df['Ticker'] == ticker].copy()\n",
    "    \n",
    "    # Get stock name from ticker_df\n",
    "    stock_name = ticker_df[ticker_df.iloc[:, 0].astype(str).str.zfill(6) == ticker].iloc[:, 1].values[0] if len(ticker_df[ticker_df.iloc[:, 0].astype(str).str.zfill(6) == ticker]) > 0 else \"Unknown\"\n",
    "    \n",
    "    # Create filename: ticker_name.parquet\n",
    "    filename = f\"{ticker}_{stock_name}.parquet\"\n",
    "    filepath = os.path.join('data', filename)\n",
    "    \n",
    "    # Save to parquet\n",
    "    stock_data.to_parquet(filepath, index=False, compression='snappy')\n",
    "\n",
    "print(f\"\\n✓ Saved {len(combined_df['Ticker'].unique())} individual stock files to 'data/' folder\")\n",
    "\n",
    "# List first 10 files as confirmation\n",
    "files = sorted(os.listdir('data'))\n",
    "print(f\"\\nFirst 10 files:\")\n",
    "for f in files[:10]:\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 parquet files in 'data/' folder\n",
      "\n",
      "Loading all files to verify...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sample files: 100%|██████████| 5/5 [00:00<00:00, 327.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "002240_고려제강.parquet:\n",
      "  Shape: (2458, 8)\n",
      "  Columns: ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Change', 'Ticker']\n",
      "  Date range: 2015-01-02 00:00:00 to 2024-12-30 00:00:00\n",
      "\n",
      "042660_대우조선해양.parquet:\n",
      "  Shape: (2458, 8)\n",
      "  Columns: ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Change', 'Ticker']\n",
      "  Date range: 2015-01-02 00:00:00 to 2024-12-30 00:00:00\n",
      "\n",
      "064960_S&T모티브.parquet:\n",
      "  Shape: (2458, 8)\n",
      "  Columns: ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Change', 'Ticker']\n",
      "  Date range: 2015-01-02 00:00:00 to 2024-12-30 00:00:00\n",
      "\n",
      "009290_광동제약.parquet:\n",
      "  Shape: (2458, 8)\n",
      "  Columns: ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Change', 'Ticker']\n",
      "  Date range: 2015-01-02 00:00:00 to 2024-12-30 00:00:00\n",
      "\n",
      "088350_한화생명.parquet:\n",
      "  Shape: (2458, 8)\n",
      "  Columns: ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Change', 'Ticker']\n",
      "  Date range: 2015-01-02 00:00:00 to 2024-12-30 00:00:00\n",
      "\n",
      "============================================================\n",
      "Sample combined data (first 5 stocks):\n",
      "============================================================\n",
      "Total rows: 12,290\n",
      "Unique stocks: 5\n",
      "\n",
      "First 10 rows:\n",
      "        Date   Open   High    Low  Close  Volume    Change  Ticker\n",
      "0 2015-01-02  27916  28017  27415  27617   27714 -0.021333  002240\n",
      "1 2015-01-05  27615  27715  26378  26916   34948 -0.025383  002240\n",
      "2 2015-01-06  26715  27050  26481  26850   18115 -0.002452  002240\n",
      "3 2015-01-07  26848  27216  26581  26783   20686 -0.002495  002240\n",
      "4 2015-01-08  26981  27049  26681  26716   11595 -0.002502  002240\n",
      "5 2015-01-09  26746  27514  26746  27383   11730  0.024966  002240\n",
      "6 2015-01-12  27115  27682  27049  27217   14146 -0.006062  002240\n",
      "7 2015-01-13  27215  27315  26881  27150   16861 -0.002462  002240\n",
      "8 2015-01-14  26982  27016  26682  26983   19170 -0.006151  002240\n",
      "9 2015-01-15  26817  26817  26649  26817   10626 -0.006152  002240\n",
      "\n",
      "✓ All parquet files loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test: Load all parquet files and verify\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_folder = 'data'\n",
    "parquet_files = [f for f in os.listdir(data_folder) if f.endswith('.parquet')]\n",
    "\n",
    "print(f\"Found {len(parquet_files)} parquet files in 'data/' folder\")\n",
    "print(\"\\nLoading all files to verify...\")\n",
    "\n",
    "# Load all files\n",
    "all_dfs = []\n",
    "for file in tqdm(parquet_files[:5], desc=\"Loading sample files\"):  # Load first 5 as sample\n",
    "    filepath = os.path.join(data_folder, file)\n",
    "    df = pd.read_parquet(filepath)\n",
    "    all_dfs.append(df)\n",
    "    print(f\"\\n{file}:\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "    print(f\"  Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "\n",
    "# Combine sample and show\n",
    "sample_combined = pd.concat(all_dfs, ignore_index=True)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Sample combined data (first 5 stocks):\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total rows: {len(sample_combined):,}\")\n",
    "print(f\"Unique stocks: {sample_combined['Ticker'].nunique()}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(sample_combined.head(10))\n",
    "\n",
    "print(f\"\\n✓ All parquet files loaded successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
