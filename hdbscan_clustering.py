import os
import re
import unicodedata
import warnings
from typing import Optional, Tuple, List, Dict

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import seaborn as sns
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import MinMaxScaler, QuantileTransformer

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜ì¡´ì„± ì²´í¬ (adjustText)
try:
    from adjustText import adjust_text
except ImportError:
    import subprocess
    # ì½”ë© ë“± í™˜ê²½ì—ì„œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì„ ê²½ìš° ìë™ ì„¤ì¹˜
    subprocess.check_call(["pip", "install", "adjustText", "-q"])
    from adjustText import adjust_text

# ë¶ˆí•„ìš”í•œ ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¹€ (ê¹”ë”í•œ ì¶œë ¥ì„ ìœ„í•¨)
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=UserWarning)


class PlotConfig:
    """
    ì°¨íŠ¸ ìŠ¤íƒ€ì¼ ë° í°íŠ¸ ì„¤ì •ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """
    @staticmethod
    def set_style():
        # ê¸°ë³¸ ìŠ¤íƒ€ì¼ ì„¤ì • (ë°°ê²½ ê²©ì ë“±)
        sns.set(style='whitegrid')
        # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€
        plt.rcParams['axes.unicode_minus'] = False
        # í•œê¸€ í°íŠ¸ ì„¤ì • ì‹¤í–‰
        PlotConfig._set_korean_font()

    @staticmethod
    def _set_korean_font():
        """
        ì‹¤í–‰ í™˜ê²½(Colab, Windows, Mac)ì„ ê°ì§€í•˜ì—¬ 
        ì ì ˆí•œ í•œê¸€ í°íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
        """
        font_candidates = ['NanumBarunGothic', 'Malgun Gothic', 'AppleGothic']
        
        # êµ¬ê¸€ ì½”ë©(Colab) í™˜ê²½ ì „ìš© ê²½ë¡œ í™•ì¸
        colab_font = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'
        if os.path.exists(colab_font):
            fm.fontManager.addfont(colab_font)
            plt.rc('font', family='NanumBarunGothic')
            return

        # ìœˆë„ìš°/ë§¥ ë“± ë¡œì»¬ í™˜ê²½ì¸ ê²½ìš° ì„¤ì¹˜ëœ í°íŠ¸ ì¤‘ í•˜ë‚˜ ì„ íƒ
        system_font = next((f for f in font_candidates if f in [f.name for f in fm.fontManager.ttflist]), 'sans-serif')
        plt.rc('font', family=system_font)


class DataLoader:
    """
    ë°ì´í„° íŒŒì¼ ë¡œë“œ ë° ì´ˆê¸° ì „ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """
    def __init__(self, base_path: str):
        self.base_path = base_path

    def load_parquets(self) -> pd.DataFrame:
        """
        ì§€ì •ëœ í´ë” ë‚´ì˜ ëª¨ë“  íŒŒì¼€(parquet) íŒŒì¼ì„ ì½ì–´ í•˜ë‚˜ë¡œ í•©ì¹©ë‹ˆë‹¤.
        """
        if not os.path.exists(self.base_path):
            print(f"[ê²½ê³ ] í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.base_path}")
            return pd.DataFrame()

        dfs = []
        for file_name in os.listdir(self.base_path):
            if not file_name.endswith('.parquet'):
                continue
            
            file_path = os.path.join(self.base_path, file_name)
            try:
                df = pd.read_parquet(file_path)
                # ì»¬ëŸ¼ëª… í‘œì¤€í™” (Date, Ticker ë“±)
                df = self._standardize_columns(df, file_name)
                dfs.append(df)
            except Exception as e:
                print(f"[ì—ëŸ¬] íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({file_name}): {e}")

        if not dfs:
            return pd.DataFrame()

        # ë°ì´í„° ë³‘í•©
        full_df = pd.concat(dfs, ignore_index=True)
        
        # ë‚ ì§œ ì»¬ëŸ¼ ì°¾ê¸° (Date, day ë“± ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´)
        date_col = next((c for c in full_df.columns if c.lower() in ['date', 'day']), 'Date')
        
        full_df[date_col] = pd.to_datetime(full_df[date_col])
        return full_df.set_index(date_col).sort_index()

    def _standardize_columns(self, df: pd.DataFrame, filename: str) -> pd.DataFrame:
        """
        ë°ì´í„°í”„ë ˆì„ì˜ ì»¬ëŸ¼ ì´ë¦„ê³¼ íƒ€ì…ì„ í‘œì¤€í™”í•©ë‹ˆë‹¤.
        """
        # ì¸ë±ìŠ¤ì— ë‚ ì§œê°€ ìˆëŠ” ê²½ìš° ë¦¬ì…‹
        if 'Date' not in df.columns and 'Ticker' not in df.columns:
            df = df.reset_index()
        
        if 'index' in df.columns:
            df.rename(columns={'index': 'Date'}, inplace=True)
        
        # íŒŒì¼ëª…ì—ì„œ í‹°ì»¤(ì¢…ëª©ì½”ë“œ) ì¶”ì¶œ
        if 'Ticker' not in df.columns:
            df['Ticker'] = filename.replace('.parquet', '')

        # ìœ ë‹ˆì½”ë“œ ë¬¸ì ì •ê·œí™” (í•œê¸€ ê¹¨ì§ ë°©ì§€)
        if df['Ticker'].dtype == object:
            df['Ticker'] = df['Ticker'].apply(lambda x: unicodedata.normalize('NFC', str(x)))

        # ì¹´í…Œê³ ë¦¬ íƒ€ì…ì€ ë¬¸ìì—´ë¡œ ë³€í™˜ (ì˜¤ë¥˜ ë°©ì§€)
        for col in df.select_dtypes(['category']).columns:
            df[col] = df[col].astype(str)
            
        return df


class FeatureEngineer:
    """
    ë°ì´í„°ì—ì„œ ë¶„ì„ì— í•„ìš”í•œ í”¼ì²˜(ì§€í‘œ)ë¥¼ ìƒì„±í•˜ê³  ê°€ê³µí•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """
    
    @staticmethod
    def parse_numeric(series: pd.Series, default: float = 0.0) -> pd.Series:
        """
        ë¬¸ìì—´ë¡œ ëœ ìˆ«ì(ì˜ˆ: '3.5%', '1,000')ë¥¼ ì‹¤ì œ ìˆ«ìí˜•ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜í•©ë‹ˆë‹¤.
        """
        if pd.api.types.is_numeric_dtype(series):
            return series.fillna(default)
        
        # ì½¤ë§ˆ(,), í¼ì„¼íŠ¸(%) ì œê±° ë° ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ í†µì¼
        clean_series = series.astype(str).str.replace(r'[,%]', '', regex=True)\
                                         .str.replace('âˆ’', '-', regex=False)\
                                         .str.replace('nan', '', regex=False)\
                                         .str.strip()
        return pd.to_numeric(clean_series, errors='coerce').fillna(default)

    def extract_dividend_metrics(self, df: pd.DataFrame) -> Tuple[pd.Series, pd.Series, pd.Series]:
        """
        ë°°ë‹¹ìˆ˜ìµë¥ (dy), ì£¼ë‹¹ë°°ë‹¹ê¸ˆ(dps), ë°°ë‹¹ì§€ê¸‰ì—¬ë¶€(flag)ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        """
        idx = df.index
        
        # ì»¬ëŸ¼ ê°€ì ¸ì˜¤ê¸° ë° ìˆ«ì ë³€í™˜
        dy = self.parse_numeric(df.get('Dividend_Yield', pd.Series(0, index=idx)))
        dps = self.parse_numeric(df.get('DPS', pd.Series(0, index=idx)))
        
        # ë‹¨ìœ„ ë³´ì •: ë°°ë‹¹ìˆ˜ìµë¥  ì¤‘ì•™ê°’ì´ 1ë³´ë‹¤ í¬ë‹¤ë©´ í¼ì„¼íŠ¸(%) ë‹¨ìœ„ë¡œ ê°„ì£¼í•˜ì—¬ 100ìœ¼ë¡œ ë‚˜ëˆ”
        if (dy > 0).any() and dy[dy > 0].median() > 1.0:
            dy = dy / 100.0

        # ë°°ë‹¹ìˆ˜ìµë¥ ì´ ë¹„ì–´ìˆë‹¤ë©´, DPS / ì¢…ê°€(Close)ë¡œ ì—­ì‚° ì‹œë„
        if (dy == 0).all() and 'Close' in df.columns and (dps > 0).any():
            close = self.parse_numeric(df['Close']).replace(0, np.nan)
            dy = (dps / close).fillna(0.0)

        # ë°°ë‹¹ ì§€ê¸‰ ì—¬ë¶€ (ìˆ˜ìµë¥ ì´ë‚˜ ë°°ë‹¹ê¸ˆì´ 0ë³´ë‹¤ í¬ë©´ True)
        payer_flag = (dy > 0) | (dps > 0)
        return dy, dps, payer_flag

    def create_features(self, snapshot: pd.DataFrame, mode: str = 'wide') -> pd.DataFrame:
        """
        í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•œ ìµœì¢… í”¼ì²˜ ë°ì´í„°í”„ë ˆì„ì„ ìƒì„±í•©ë‹ˆë‹¤.
        mode: 'wide' (ì „ì²´, ë°°ë‹¹X í¬í•¨) | 'div_only' (ë°°ë‹¹ ì§€ê¸‰ ì¢…ëª©ë§Œ)
        """
        if snapshot.empty:
            return pd.DataFrame()

        base = snapshot.set_index('Ticker') if 'Ticker' in snapshot.columns else snapshot.copy()
        dy, dps, payer = self.extract_dividend_metrics(base)

        # ëª¨ë“œì— ë”°ë¥¸ ë°ì´í„° í•„í„°ë§
        if mode == 'div_only':
            base = base[payer]
            dy, dps, payer = dy.loc[base.index], dps.loc[base.index], payer.loc[base.index]

        if base.empty:
            return pd.DataFrame()

        # ë³´ì¡° ì§€í‘œ íŒŒì‹± (ì´ê²©ë„, ì˜ì—…ì´ìµ)
        disp = self.parse_numeric(base.get('Disparity_60d', pd.Series(0, index=base.index)))
        op_val = self.parse_numeric(base.get('ì˜ì—…ì´ìµ', pd.Series(0, index=base.index)))
        
        # ì‹œê°€ì´ì•¡ ê³„ì‚° (Marcap ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¢…ê°€*ê±°ë˜ëŸ‰ìœ¼ë¡œ ëŒ€ì²´)
        if 'Marcap' in base.columns:
            marcap = self.parse_numeric(base['Marcap'])
        elif 'Close' in base.columns and 'Volume' in base.columns:
            marcap = self.parse_numeric(base['Close']) * self.parse_numeric(base['Volume'])
        else:
            marcap = pd.Series(0, index=base.index)

        # ê±°ë˜ëŸ‰ ë¹„ìœ¨ (í˜„ì¬ ê±°ë˜ëŸ‰ / 60ì¼ í‰ê· )
        vol = self.parse_numeric(base.get('Volume', pd.Series(0, index=base.index)))
        vol_avg = self.parse_numeric(base.get('vol_60', pd.Series(1, index=base.index))).replace(0, 1)
        vol_ratio = vol / vol_avg

        # ë°ì´í„° ë¶„í¬ ì •ê·œí™” (Quantile Transformation)
        qt = QuantileTransformer(n_quantiles=min(1000, len(base)), output_distribution='normal', random_state=42)
        
        # Xì¶• ì„¤ê³„ (ë°°ë‹¹ ëª¨ë©˜í…€)
        if mode == 'wide':
            # Wide ëª¨ë“œ: ë°°ë‹¹ì£¼ì™€ ë¹„ë°°ë‹¹ì£¼ë¥¼ ì‹œê°ì ìœ¼ë¡œ í™• ë²Œë ¤ë†“ê¸° ìœ„í•´ ê°€ì‚°ì  ë¶€ì—¬
            dy_spread = dy.copy()
            dy_spread[payer] += 2.0 
            x_input = dy_spread.values.reshape(-1, 1)
        else:
            x_input = dy.values.reshape(-1, 1)

        dy_norm = qt.fit_transform(x_input).ravel()
        disp_norm = qt.fit_transform(disp.values.reshape(-1, 1)).ravel()
        vol_norm = qt.fit_transform(vol_ratio.values.reshape(-1, 1)).ravel()

        # ìµœì¢… ì ìˆ˜ ì‚°ì¶œ (ê°€ì¤‘ì¹˜: ë°°ë‹¹ 60% + ì´ê²©ë„ 25% + ê±°ë˜ëŸ‰ 15%)
        x_raw = (dy_norm * 0.6) + (disp_norm * 0.25) + (vol_norm * 0.15)
        x_final = MinMaxScaler().fit_transform(x_raw.reshape(-1, 1)).ravel()
        
        # Yì¶•: ì‹¤ì (ì˜ì—…ì´ìµ) ìˆœìœ„ (í¼ì„¼íŠ¸ ë­í¬)
        y_final = op_val.rank(pct=True).values

        return pd.DataFrame({
            'X_Momentum': x_final,
            'Y_Fundamental': y_final,
            'MarketCap': marcap.values,
            'Dividend_Yield': dy.values,
            'DPS': dps.values,
            'Payer_Flag': payer.values,
        }, index=base.index)


class RallyMapVisualizer:
    """
    ë°ì´í„°ë¥¼ ê·¸ë£¹í™”(í´ëŸ¬ìŠ¤í„°ë§)í•˜ê³  ì‹œê°í™”(ì°¨íŠ¸)í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """
    
    def __init__(self, drive_path: str):
        self.drive_path = drive_path

    def _assign_labels(self, row: pd.Series, mode: str) -> str:
        """
        ì¢Œí‘œ(X, Y)ì— ë”°ë¼ ê·¸ë£¹ ì´ë¦„ì„ ë¶™ì—¬ì¤ë‹ˆë‹¤.
        """
        cx, cy = row['X_Momentum'], row['Y_Fundamental']
        if mode == 'wide':
            # Wide ëª¨ë“œ: Xì¶• ì ˆë°˜ ê¸°ì¤€ìœ¼ë¡œ ë¹„ë°°ë‹¹/ë°°ë‹¹ ë‚˜ëˆ”
            if cx > 0.5:
                return "1. ì‚°íƒ€ ë ë¦¬ ì£¼ë„ì£¼" if cy > 0.6 else "3. ë°°ë‹¹ í…Œë§ˆì£¼"
            else:
                return "2. ì„±ì¥ ìš°ëŸ‰ì£¼" if cy > 0.6 else "4. ë‚™í­ ê³¼ëŒ€ì£¼"
        else:
            # Div Only ëª¨ë“œ: ìƒëŒ€ì  4ë¶„ë©´
            if cx > 0.6 and cy > 0.6: return "1. ì‚°íƒ€ ë ë¦¬ ì£¼ë„ì£¼"
            if cx <= 0.6 and cy > 0.6: return "2. ì €í‰ê°€ ì‹¤ì ì£¼"
            if cx > 0.6 and cy <= 0.6: return "3. ê³ ë°°ë‹¹ í…Œë§ˆì£¼"
            return "4. ë°°ë‹¹ì£¼ ì†Œì™¸"

    def run(self, target_date: pd.Timestamp, data: pd.DataFrame, mode: str, eps: float, min_samples: int):
        """
        ì‹¤ì œ ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜ì…ë‹ˆë‹¤.
        """
        title_mode = "Wide Spread (ì „ì²´)" if mode == 'wide' else "Dividend Only (ë°°ë‹¹ì£¼ë§Œ)"
        print(f"\nğŸš€ [ë¶„ì„ ì‹œì‘: {title_mode}] ê¸°ì¤€ì¼: {target_date.date()}")

        try:
            snapshot = data.loc[target_date].copy()
            if isinstance(snapshot, pd.Series):
                snapshot = snapshot.to_frame().T
        except KeyError:
            print("í•´ë‹¹ ë‚ ì§œì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        fe = FeatureEngineer()
        feats = fe.create_features(snapshot, mode=mode)
        
        if feats.empty:
            print("í”¼ì²˜ ìƒì„± ì‹¤íŒ¨: ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì»¬ëŸ¼ì„ í™•ì¸í•˜ì„¸ìš”.")
            return

        # í´ëŸ¬ìŠ¤í„°ë§ (DBSCAN ì•Œê³ ë¦¬ì¦˜)
        X = feats[['X_Momentum', 'Y_Fundamental']].values
        db = DBSCAN(eps=eps, min_samples=min_samples).fit(X)
        feats['Cluster_ID'] = db.labels_
        feats['Cluster_Name'] = feats.apply(lambda r: self._assign_labels(r, mode), axis=1)

        self._plot_map(feats, target_date, title_mode)
        self._save_results(feats, target_date, mode)

    def _plot_map(self, df: pd.DataFrame, date: pd.Timestamp, title_suffix: str):
        """
        ì‚°ì ë„(Scatter Plot)ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
        """
        plt.figure(figsize=(15, 9))
        
        # ê·¸ë£¹ë³„ ìƒ‰ìƒ ì§€ì •
        unique_groups = sorted(df['Cluster_Name'].unique())
        palette = sns.color_palette("bright", n_colors=len(unique_groups))
        color_map = dict(zip(unique_groups, palette))

        # ë…¸ì´ì¦ˆ(ì–´ëŠ ê·¸ë£¹ì—ë„ ì†í•˜ì§€ ëª»í•œ ì¢…ëª©)ëŠ” íšŒìƒ‰ìœ¼ë¡œ ì—°í•˜ê²Œ í‘œì‹œ
        noise = df[df['Cluster_ID'] == -1]
        if not noise.empty:
            plt.scatter(noise['X_Momentum'], noise['Y_Fundamental'], c='#EEEEEE', 
                        s=15, alpha=0.35, label='Noise (ê°œë³„ì¢…ëª©)', zorder=1)

        # ë©”ì¸ ê·¸ë£¹ ê·¸ë¦¬ê¸°
        text_labels = []
        for name in unique_groups:
            subset = df[(df['Cluster_Name'] == name) & (df['Cluster_ID'] != -1)]
            if subset.empty: continue
            
            is_leader = "ì‚°íƒ€" in name  # ì£¼ë„ì£¼ ê·¸ë£¹ ê°•ì¡°
            plt.scatter(subset['X_Momentum'], subset['Y_Fundamental'], 
                        c=[color_map[name]], 
                        s=np.log1p(subset['MarketCap']) * 4 + 20,  # ì‹œì´ í´ìˆ˜ë¡ ì  í¬ê¸° í™•ëŒ€
                        alpha=1.0 if is_leader else 0.85,
                        edgecolors='black' if is_leader else 'white',
                        linewidths=0.7, label=name, zorder=5)

            # ë¼ë²¨ë§: ê° ê·¸ë£¹ì—ì„œ ì‹œê°€ì´ì•¡ 1ë“± ì¢…ëª© ì´ë¦„í‘œ ë¶™ì´ê¸°
            top_ticker = subset.nlargest(1, 'MarketCap').index[0]
            text_labels.append(top_ticker)

        # ì¶”ê°€ ë¼ë²¨ë§: ë°°ë‹¹ìˆ˜ìµë¥  ì „ì²´ TOP 3 ì¢…ëª©
        text_labels += df.nlargest(3, 'Dividend_Yield').index.tolist()
        
        # í…ìŠ¤íŠ¸ ê²¹ì¹¨ ë°©ì§€ (adjustText ì‚¬ìš©)
        texts = [plt.text(df.loc[t, 'X_Momentum'], df.loc[t, 'Y_Fundamental'], str(t), 
                 fontsize=11, fontweight='bold') for t in set(text_labels)]
        
        adjust_text(texts, arrowprops=dict(arrowstyle='-', color='gray', alpha=0.4))

        plt.title(f"Year-End Rally Map ({title_suffix})\n{date.date()}", fontsize=18, fontweight='bold', pad=20)
        plt.xlabel("Dividend Momentum Score (ë°°ë‹¹ ëª¨ë©˜í…€)", fontsize=12)
        plt.ylabel("Fundamental Rank (ì‹¤ì  ì²´ë ¥)", fontsize=12)
        plt.xlim(-0.05, 1.05)
        plt.ylim(-0.05, 1.05)
        plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', fontsize=11)
        plt.tight_layout()
        plt.show()

    def _save_results(self, df: pd.DataFrame, date: pd.Timestamp, mode: str):
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        """
        filename = f"Rally_Map_{mode.upper()}_{date.strftime('%Y%m%d')}.csv"
        path = os.path.join(self.drive_path, filename)
        df.reset_index().rename(columns={'index': 'Ticker'}).to_csv(path, index=False)
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {path}")


# =========================================
# ë©”ì¸ ì‹¤í–‰ ì˜ì—­
# =========================================
if __name__ == "__main__":
    from google.colab import drive
    drive.mount('/content/drive')
    
    DRIVE_PATH = '/content/drive/MyDrive/data'
    
    # 1. ì„¤ì • ì´ˆê¸°í™”
    PlotConfig.set_style()
    loader = DataLoader(DRIVE_PATH)
    visualizer = RallyMapVisualizer(DRIVE_PATH)

    # 2. ë°ì´í„° ë¡œë“œ
    full_data = loader.load_parquets()

    if not full_data.empty:
        # ê°€ì¥ ìµœê·¼ ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°
        last_date = sorted(full_data.index.unique())[-1]
        
        # 3. ì‹œë‚˜ë¦¬ì˜¤ë³„ ì‹¤í–‰
        # A) Wide Spread: ì „ì²´ ì¢…ëª© ëŒ€ìƒ, ë°°ë‹¹ ìœ ë¬´ë¡œ ì¢Œìš° ê°•ì œ ë¶„ë¦¬
        visualizer.run(target_date=last_date, data=full_data, mode='wide', eps=0.06, min_samples=6)

        # B) Dividend Only: ë°°ë‹¹ ì£¼ëŠ” ì¢…ëª©ë§Œ ë‚¨ê²¨ì„œ ë¹„êµ
        visualizer.run(target_date=last_date, data=full_data, mode='div_only', eps=0.07, min_samples=4)
    else:
        print("[ì—ëŸ¬] ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë“œë¼ì´ë¸Œ ê²½ë¡œì™€ íŒŒì¼ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
